{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "@Author: Shital Bajait\n",
    "@Date: 22-03-2022 15:56:00\n",
    "@Last Modified by: Shital Bajait \n",
    "@Last Modified time: 22-03-2022 15:56:00\n",
    "@Title : Operation using spark sql on cpu log data files \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/27 19:06:26 WARN Utils: Your hostname, shital-VivoBook-ASUS-Laptop-X505ZA-X505ZA resolves to a loopback address: 127.0.1.1; using 192.168.0.241 instead (on interface wlp1s0)\n",
      "22/03/27 19:06:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/27 19:06:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/27 19:06:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName(\"cpu data late coming\")\\\n",
    "                    .getOrCreate()\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"file:///home/shital/Desktop/CFP/cpu_log_data/CpuLogData2019-09-20.csv\", header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------+------+\n",
      "|           user_name|           DateTime|keyboard| mouse|\n",
      "+--------------------+-------------------+--------+------+\n",
      "|sharlawar77@gmail...|2019-09-20 09:05:01|    39.0| 210.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:10:01|     0.0|   0.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:15:02|    99.0| 575.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:20:06|     9.0|1657.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:25:05|   298.0| 356.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:30:05|   170.0| 221.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:35:06|   270.0|  48.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:40:05|   206.5| 364.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:45:05|   248.0| 227.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:50:05|   304.5|1638.0|\n",
      "|sharlawar77@gmail...|2019-09-20 09:55:06|   154.5| 213.0|\n",
      "|  iamnzm@outlook.com|2019-09-20 10:00:01|    23.0| 208.0|\n",
      "|sharlawar77@gmail...|2019-09-20 10:00:06|    88.0| 261.0|\n",
      "|  iamnzm@outlook.com|2019-09-20 10:05:01|     2.0|  65.0|\n",
      "|sharlawar77@gmail...|2019-09-20 10:05:07|    14.0| 135.0|\n",
      "|  iamnzm@outlook.com|2019-09-20 10:10:01|     0.0|   0.0|\n",
      "|sharlawar77@gmail...|2019-09-20 10:10:05|    26.0|1439.0|\n",
      "|sharlawar77@gmail...|2019-09-20 10:15:01|     4.0| 178.0|\n",
      "|  iamnzm@outlook.com|2019-09-20 10:15:01|    14.0| 355.0|\n",
      "|  iamnzm@outlook.com|2019-09-20 10:20:01|     0.0| 161.0|\n",
      "+--------------------+-------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.select(\"user_name\",\"DateTime\",\"keyboard\",\"mouse\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/27 19:07:19 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"late_user_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           user_name|count|\n",
      "+--------------------+-----+\n",
      "|salinabodale73@gm...|   50|\n",
      "|sharlawar77@gmail...|   66|\n",
      "|rahilstar11@gmail...|   51|\n",
      "|  iamnzm@outlook.com|   55|\n",
      "|markfernandes66@g...|   51|\n",
      "|damodharn21@gmail...|   49|\n",
      "|bhagyashrichalke2...|   46|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.sql(\"select user_name from late_user_count\").groupBy(\"user_name\").count()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|late_coming_user|\n",
      "+----------------+\n",
      "|              46|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(f.min(\"count\").alias(\"late_coming_user\")).show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
